
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://pytorch.apachecn.org/2.0/docs/notes/extending/">
      
      
        <link rel="prev" href="../ddp/">
      
      
        <link rel="next" href="../extending.func/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.10">
    
    
      
        <title>Extending PyTorch - 【布客】PyTorch 中文翻译</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.7e359304.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13.274 9.537v-.001l-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074ZM4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5ZM4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75Z"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.484 4.484 0 0 1-.563-1.191 3.835 3.835 0 0 1-.05-2.063 4.647 4.647 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .748.748 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.425 2.425 0 0 1-.507-.441 3.075 3.075 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19a.884.884 0 0 1 .01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.737 3.737 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353V.75Z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.756 2.756 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6.24 6.24 0 0 0-.26.16.952.952 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661.103-.067.207-.132.313-.195l.007-.004c.1-.061.182-.11.258-.161a.969.969 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.612.612 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1.01 1.01 0 0 0-.34.398ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343h-.001a8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746Zm1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275ZM6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L6.94 8 4.97 6.03a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018Z"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.249 1.249 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429Zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006a.036.036 0 0 0-.004-.009l-.006-.006-.008-.001c-.003 0-.006.002-.009.004Z"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.488 3.488 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327c0 .1-.009.197-.025.292.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5c0 .409-.049.806-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A4.997 4.997 0 0 1 8 16a4.997 4.997 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5.036 5.036 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.677 1.677 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06Zm.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.172.172 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173Z"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.746.746 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5Zm4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0Z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-header__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.apachecn.org/img/logo/logo_green.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            【布客】PyTorch 中文翻译
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Extending PyTorch
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="【布客】PyTorch 中文翻译" class="md-nav__button md-logo" aria-label="【布客】PyTorch 中文翻译" data-md-component="logo">
      
  <img src="https://data.apachecn.org/img/logo/logo_green.png" alt="logo">

    </a>
    【布客】PyTorch 中文翻译
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/apachecn/pytorch-doc-zh" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    apachecn/pytorch-doc-zh
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 新特性
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 新特性
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V2.0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V2.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.13/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.13
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.12/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.12
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.11
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.10
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.9
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.8
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.7
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.6
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LatestChanges/PyTorch_V1.2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    V1.2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch 2.x 中文文档 & 教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            PyTorch 2.x 中文文档 & 教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            中文教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PyTorch Recipes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            PyTorch Recipes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/recipes/recipes_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Recipes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/prototype/prototype_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    See All Prototype Recipes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learn the Basics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/quickstart_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/tensorqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/data_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets & DataLoaders
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/transforms_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/buildmodel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build the Neural Network
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/autogradqs_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Differentiation with torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/optimization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Model Parameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/basics/saveloadrun_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Save and Load the Model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" >
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to PyTorch on YouTube
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            Introduction to PyTorch on YouTube
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch - YouTube Series
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/introyt1_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/tensors_deeper_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to PyTorch Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/autogradyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Fundamentals of Autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/modelsyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Models with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/tensorboardyt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch TensorBoard Support
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/trainingyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/introyt/captumyt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Understanding with Captum
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_4" >
        
          
          <label class="md-nav__link" for="__nav_3_1_4" id="__nav_3_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Learning PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_4">
            <span class="md-nav__icon md-icon"></span>
            Learning PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/deep_learning_60min_blitz/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deep Learning with PyTorch: A 60 Minute Blitz
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/pytorch_with_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning PyTorch with Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/nn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is torch.nn really?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/tensorboard_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualizing Models, Data, and Training with TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_5" >
        
          
          <label class="md-nav__link" for="__nav_3_1_5" id="__nav_3_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Image and Video
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_5">
            <span class="md-nav__icon md-icon"></span>
            Image and Video
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/torchvision_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision Object Detection Finetuning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/fgsm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adversarial Example Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/dcgan_faces_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DCGAN Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/spatial_transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial Transformer Networks Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_6" >
        
          
          <label class="md-nav__link" for="__nav_3_1_6" id="__nav_3_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Audio
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_6">
            <span class="md-nav__icon md-icon"></span>
            Audio
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_io_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio I/O
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_resampling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Resampling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_data_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Data Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_feature_extractions_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Extractions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_feature_augmentation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Feature Augmentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/audio_datasets_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Audio Datasets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/speech_recognition_pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speech Recognition with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/text_to_speech_with_torchaudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-speech with Tacotron2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/forced_alignment_with_torchaudio_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forced Alignment with Wav2Vec2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_7" >
        
          
          <label class="md-nav__link" for="__nav_3_1_7" id="__nav_3_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_7">
            <span class="md-nav__icon md-icon"></span>
            Text
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/transformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Modeling with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/bettertransformer_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fast Transformer Inference with Better Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/char_rnn_classification_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Classifying Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/char_rnn_generation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Generating Names with a Character-Level RNN
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/seq2seq_translation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLP From Scratch: Translation with a Sequence to Sequence Network and Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/text_sentiment_ngrams_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text classification with the torchtext library
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/translation_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Translation with nn.Transformer and torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/torchtext_custom_dataset_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocess custom text dataset using Torchtext
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_8" >
        
          
          <label class="md-nav__link" for="__nav_3_1_8" id="__nav_3_1_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_8">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_9" >
        
          
          <label class="md-nav__link" for="__nav_3_1_9" id="__nav_3_1_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reinforcement Learning
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_9">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/reinforcement_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (DQN) Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/reinforcement_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reinforcement Learning (PPO) with TorchRL Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/mario_rl_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a Mario-playing RL Agent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_10" >
        
          
          <label class="md-nav__link" for="__nav_3_1_10" id="__nav_3_1_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deploying PyTorch Models in Production
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_10">
            <span class="md-nav__icon md-icon"></span>
            Deploying PyTorch Models in Production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/onnx/intro_onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to ONNX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/flask_rest_api_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deploying PyTorch in Python via a REST API with Flask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/Intro_to_TorchScript_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/cpp_export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loading a TorchScript Model in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/super_resolution_with_onnxruntime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/realtime_rpi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Real Time Inference on Raspberry Pi 4 (30 fps!)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_11" >
        
          
          <label class="md-nav__link" for="__nav_3_1_11" id="__nav_3_1_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Transforms with FX
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_11">
            <span class="md-nav__icon md-icon"></span>
            Code Transforms with FX
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/fx_conv_bn_fuser/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Convolution/Batch Norm fuser in FX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/fx_profiling_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Building a Simple CPU Performance Profiler with FX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_12" >
        
          
          <label class="md-nav__link" for="__nav_3_1_12" id="__nav_3_1_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Frontend APIs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_12">
            <span class="md-nav__icon md-icon"></span>
            Frontend APIs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/memory_format_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Channels Last Memory Format in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/forward_ad_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Forward-mode Automatic Differentiation (Beta)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/jacobians_hessians/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Jacobians, Hessians, hvp, vhp, and more: composing function transforms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/ensembling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model ensembling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/per_sample_grads/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Per-sample-gradients
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/cpp_frontend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the PyTorch C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/torch-script-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Parallelism in TorchScript
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/cpp_autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd in C++ Frontend
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_13" >
        
          
          <label class="md-nav__link" for="__nav_3_1_13" id="__nav_3_1_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_13">
            <span class="md-nav__icon md-icon"></span>
            Extending PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/custom_function_double_backward_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Double Backward with Custom Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/custom_function_conv_bn_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fusing Convolution and Batch Norm using Custom Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom C++ and CUDA Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/torch_script_custom_ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Operators
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/torch_script_custom_classes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending TorchScript with Custom C++ Classes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registering a Dispatched Operator in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/extend_dispatcher/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending dispatcher for a new backend in C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/privateuseone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Facilitating New Backend Integration by PrivateUse1
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_14" >
        
          
          <label class="md-nav__link" for="__nav_3_1_14" id="__nav_3_1_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_14">
            <span class="md-nav__icon md-icon"></span>
            Model Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Profiling your PyTorch Module
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/tensorboard_profiler_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Profiler With TensorBoard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/hyperparameter_tuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hyperparameter tuning with Ray Tune
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/vt_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimizing Vision Transformer Model for Deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/parametrizations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametrizations Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/pruning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pruning Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/dynamic_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on an LSTM Word Language Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/dynamic_quantization_bert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Dynamic Quantization on BERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/quantized_transfer_learning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Quantized Transfer Learning for Computer Vision Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/static_quantization_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (beta) Static Quantization with Eager Mode in PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/torchserve_with_ipex/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/torchserve_with_ipex_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grokking PyTorch Intel CPU performance from first principles (Part 2)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/nvfuser_intro_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started - Accelerate Your Scripts with nvFuser
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/ax_multiobjective_nas_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi-Objective NAS with Ax
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/torch_compile_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.compile Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/inductor_debug_cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inductor CPU backend debugging and profiling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/scaled_dot_product_attention_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/scaled_dot_product_attention_tutorial%23using-sdpa-with-torch-compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using SDPA with torch.compile
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/scaled_dot_product_attention_tutorial%23conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/knowledge_distillation_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge Distillation Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_15" >
        
          
          <label class="md-nav__link" for="__nav_3_1_15" id="__nav_3_1_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Parallel and Distributed Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_15">
            <span class="md-nav__icon md-icon"></span>
            Parallel and Distributed Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/distributed/home/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed and Parallel Training Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/dist_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Distributed Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/ddp_series_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel in PyTorch - Video Tutorials
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/model_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single-Machine Model Parallel Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed Data Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/dist_tuto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Distributed Applications with PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/FSDP_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Fully Sharded Data Parallel(FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/FSDP_adavnced_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advanced Model Training with Fully Sharded Data Parallel (FSDP)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/process_group_cpp_extension_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Process Group Backends Using Cpp Extensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/rpc_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/rpc_param_server_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing a Parameter Server Using Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/dist_pipeline_parallel_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Pipeline Parallelism Using RPC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/rpc_async_execution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implementing Batch RPC Processing Using Asynchronous Executions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/rpc_ddp_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Combining Distributed DataParallel with Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/pipeline_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/ddp_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training Transformer models using Distributed Data Parallel and Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/generic_join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training with Uneven Inputs Using the Join Context Manager
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_16" >
        
          
          <label class="md-nav__link" for="__nav_3_1_16" id="__nav_3_1_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mobile
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_16">
            <span class="md-nav__icon md-icon"></span>
            Mobile
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/deeplabv3_on_ios/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on iOS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/deeplabv3_on_android/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image Segmentation DeepLabV3 on Android
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_17" >
        
          
          <label class="md-nav__link" for="__nav_3_1_17" id="__nav_3_1_17_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Recommendation Systems
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_17">
            <span class="md-nav__icon md-icon"></span>
            Recommendation Systems
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/intermediate/torchrec_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to TorchRec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/advanced/sharding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring TorchRec sharding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_18" >
        
          
          <label class="md-nav__link" for="__nav_3_1_18" id="__nav_3_1_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Multimodality
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_18">
            <span class="md-nav__icon md-icon"></span>
            Multimodality
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/beginner/flava_finetuning_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchMultimodal Tutorial: Finetuning FLAVA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    中文文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            中文文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2_2" id="__nav_3_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Community
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_2">
            <span class="md-nav__icon md-icon"></span>
            Community
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../community/build_ci_governance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Governance | Build + CI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../community/contribution_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Contribution Guide
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../community/design/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Design Philosophy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../community/governance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Governance | Mechanics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../community/persons_of_interest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Governance | Maintainers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2_3" id="__nav_3_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Developer Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2_3">
            <span class="md-nav__icon md-icon"></span>
            Developer Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../amp_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA Automatic Mixed Precision examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd mechanics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../broadcasting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Broadcasting semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpu_threading_torchscript_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU threading and TorchScript inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Data Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Extending PyTorch
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#torchautograd" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch.autograd¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch.autograd¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      何时使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      何时不使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      如何使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      示例 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-setup_context" class="md-nav__link">
    <span class="md-ellipsis">
      组合或单独的 forward() 和 setup_context()¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ad" class="md-nav__link">
    <span class="md-ellipsis">
      转发模式 AD ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfunc-torchvmap" class="md-nav__link">
    <span class="md-ellipsis">
      torch.func 转换和/或 torch.vmap()¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchnn" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch.nn¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch.nn¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module" class="md-nav__link">
    <span class="md-ellipsis">
      添加一个 Module¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-python-api" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch Python API ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch Python API ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-torch" class="md-nav__link">
    <span class="md-ellipsis">
      使用类似 Tensor 类型扩展 torch ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchtensor" class="md-nav__link">
    <span class="md-ellipsis">
      子类化 torch.Tensor¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-torch_1" class="md-nav__link">
    <span class="md-ellipsis">
      使用 Tensor 包装类型扩展 torch ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#__torch_function__" class="md-nav__link">
    <span class="md-ellipsis">
      对定义 __torch_function__ 的多种类型进行操作¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-api" class="md-nav__link">
    <span class="md-ellipsis">
      测试 PyTorch API 覆盖的覆盖率 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-api" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch 原生 API ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-api_1" class="md-nav__link">
    <span class="md-ellipsis">
      使用模式扩展所有 torch API ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#c" class="md-nav__link">
    <span class="md-ellipsis">
      编写自定义 C++ 扩展 ¶
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../extending.func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending torch.func with autograd.Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frequently Asked Questions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradcheck/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradcheck mechanics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HIP (ROCm) semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../large_scale_deployments/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Features for large-scale deployments
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MPS backend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiprocessing best practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numerical_accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Numerical accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../randomness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reproducibility
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../serialization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization semantics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../windows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_4" >
        
          
          <label class="md-nav__link" for="__nav_3_2_4" id="__nav_3_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Language Bindings
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_4">
            <span class="md-nav__icon md-icon"></span>
            Language Bindings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cpp_index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C++
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/javadoc" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Javadoc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deploy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch::deploy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_5" >
        
          
          <label class="md-nav__link" for="__nav_3_2_5" id="__nav_3_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_5">
            <span class="md-nav__icon md-icon"></span>
            Python API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn.functional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Tensor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensor_attributes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Attributes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensor_view/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Views
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../amp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.amp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../autograd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.autograd
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../library/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.library
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cpu
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.cuda
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch_cuda_memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understanding CUDA Memory Usage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch_cuda_memory#generating-a-snapshot.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generating a Snapshot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch_cuda_memory#using-the-visualizer.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using the visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch_cuda_memory#snapshot-api-reference.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Snapshot API Reference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.mps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../backends/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed.algorithms.join/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.algorithms.join
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed.elastic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.elastic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.fsdp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed.optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed.tensor.parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.tensor.parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributed.checkpoint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributed.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../distributions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch.compiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.compiler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.fft
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.func
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../futures/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.futures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.fx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../jit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.jit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linalg/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.linalg
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../signal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.signal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../special/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.special
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../torch.overrides/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.overrides
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../package/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.package
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../profiler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.profiler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn.init/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nn.init
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../onnx/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.onnx
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.optim
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../complex_numbers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Complex Numbers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ddp_comm_hooks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDP Communication Hooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pipeline Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rpc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed RPC Framework
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../random/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.random
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../masked/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.masked
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nested/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.nested
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../sparse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.sparse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.testing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../benchmark_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.benchmark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../bottleneck/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.bottleneck
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../checkpoint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.checkpoint
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cpp_extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.cpp_extension
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../jit_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.jit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dlpack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.dlpack
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mobile_optimizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.mobile_optimizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_zoo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.model_zoo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tensorboard/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.utils.tensorboard
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../type_info/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Type Info
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../named_tensor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Named Tensors
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../name_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Named Tensors operator coverage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../config_mod/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch.__config__
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torch._logging
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_6" >
        
          
          <label class="md-nav__link" for="__nav_3_2_6" id="__nav_3_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Libraries
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_6">
            <span class="md-nav__icon md-icon"></span>
            Libraries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/audio/stable" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchaudio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/data" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchData
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/torchrec" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchRec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/serve" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchServe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/text/stable" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchtext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/vision/stable" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    torchvision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../https:/pytorch.org/xla" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch on XLA Devices
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.7 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.4 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch1x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 1.0 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.4 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.3 中文文档 & 教程
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://pytorch0x.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch 0.2 中文文档
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contrib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    贡献指南
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/about" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://www.apachecn.org/join" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加入我们
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://docs.apachecn.org" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中文资源合集
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#torchautograd" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch.autograd¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch.autograd¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      何时使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      何时不使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      如何使用 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      示例 ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#forward-setup_context" class="md-nav__link">
    <span class="md-ellipsis">
      组合或单独的 forward() 和 setup_context()¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ad" class="md-nav__link">
    <span class="md-ellipsis">
      转发模式 AD ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchfunc-torchvmap" class="md-nav__link">
    <span class="md-ellipsis">
      torch.func 转换和/或 torch.vmap()¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchnn" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch.nn¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch.nn¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module" class="md-nav__link">
    <span class="md-ellipsis">
      添加一个 Module¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-python-api" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch Python API ¶
    </span>
  </a>
  
    <nav class="md-nav" aria-label="扩展 torch Python API ¶">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-torch" class="md-nav__link">
    <span class="md-ellipsis">
      使用类似 Tensor 类型扩展 torch ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchtensor" class="md-nav__link">
    <span class="md-ellipsis">
      子类化 torch.Tensor¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-torch_1" class="md-nav__link">
    <span class="md-ellipsis">
      使用 Tensor 包装类型扩展 torch ¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#__torch_function__" class="md-nav__link">
    <span class="md-ellipsis">
      对定义 __torch_function__ 的多种类型进行操作¶
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-api" class="md-nav__link">
    <span class="md-ellipsis">
      测试 PyTorch API 覆盖的覆盖率 ¶
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-api" class="md-nav__link">
    <span class="md-ellipsis">
      扩展 torch 原生 API ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torch-api_1" class="md-nav__link">
    <span class="md-ellipsis">
      使用模式扩展所有 torch API ¶
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#c" class="md-nav__link">
    <span class="md-ellipsis">
      编写自定义 C++ 扩展 ¶
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/apachecn/pytorch-doc-zh/edit/master/docs/2.0/docs/notes/extending.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/apachecn/pytorch-doc-zh/raw/master/docs/2.0/docs/notes/extending.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


<h1 id="pytorch">扩展 PyTorch <a href="#extending-pytorch" title="永久链接到此标题">¶</a></h1>
<blockquote>
<p>译者：<a href="https://github.com/jiangzhonglian">片刻小哥哥</a></p>
<p>项目地址：<a href="https://pytorch.apachecn.org/2.0/docs/notes/extending">https://pytorch.apachecn.org/2.0/docs/notes/extending</a></p>
<p>原始地址：<a href="https://pytorch.org/docs/stable/notes/extending.html">https://pytorch.org/docs/stable/notes/extending.html</a></p>
</blockquote>
<p>在这篇文章中，我们将介绍扩展 <a href="../nn.html#module-torch.nn" title="torch.nn"><code>torch.nn</code></a> 、 <a href="../autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> 、 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> ，以及编写自定义 C++ 扩展。</p>
<h2 id="torchautograd">扩展 <a href="../autograd.html#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a><a href="#extending-torch-autograd" title="永久链接到此标题">¶</a></h2>
<p>向 <a href="../autograd.html#module-torch.autograd" title="torch.autograd"><code>autograd</code></a> 添加操作需要实现一个新的 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 每个操作的子类。回想一下，函数是 <a href="../autograd.html#module-torch.autograd" title="torch.autograd"><code>autograd</code></a> 用于对操作历史记录和计算梯度进行编码的函数。</p>
<p>本文档的第一部分重点介绍后向模式 AD，因为它是使用最广泛的功能。最后的一节讨论了前向模式 AD 的扩展。</p>
<h3 id="_1">何时使用 <a href="#when-to-use" title="此标题的永久链接">¶</a></h3>
<p>一般来说，如果您想在模型中执行不可微分或依赖于非 PyTorch 库(例如 NumPy)的计算，但仍希望您的操作与其他操作链接并使用 autograd 引擎，请实现自定义函数。</p>
<p>在某些情况下，自定义函数也可用于提高性能和内存使用率：如果您使用 <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">C++ 扩展</a> 实现前向和后向传递，您可以将它们包装在 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 中以与 autogradengine 交互。如果您想减少为向后传递保存的缓冲区数量，可以使用自定义函数将操作组合在一起。</p>
<h3 id="_2">何时不使用 <a href="#when-not-to-use" title="永久链接到此标题">¶</a></h3>
<p>如果您已经可以根据 PyTorch 的内置操作编写函数，则其后向图(很可能)已经能够由 autograd 记录。在这种情况下，您不需要自己实现向后函数。考虑使用普通的 Python 函数。</p>
<p>如果您需要维护状态，即可训练参数，您应该(也)使用自定义模块。有关扩展 <a href="../nn.html#module-torch.nn" title="torch.nn"><code>torch.nn</code></a> 的更多信息，请参阅下面的部分。</p>
<p>如果您想在向后传递过程中改变梯度或执行副作用，请考虑注册一个<a href="https://pytorch.org/docs/stable/generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook">tensor</a> 或 <a href="https://pytorch.org/docs/stable/notes/modules.html#module-hooks">模块</a> 钩子。</p>
<h3 id="_3">如何使用 <a href="#how-to-use" title="此标题的永久链接">¶</a></h3>
<p>采取以下步骤： 1．子类 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 并实现 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> ,(可选) <code>setup_context()</code> 和 <a href="../generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward" title="torch.autograd.Function.backward"><code>backward()</code></a> 方法.2.对 ctx 参数调用正确的方法。3.声明你的函数是否支持<a href="https://pytorch.org/tutorials/intermediate/custom_function_double_backward_tutorial.html">double backward</a>.4.使用 gradcheck 验证您的渐变是否正确。</p>
<p><strong>步骤1：</strong>子类化 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 后，您需要定义 3 个方法：</p>
<ul>
<li><a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 是执行该操作的代码。它可以接受任意数量的参数，如果您指定默认值，其中一些参数是可选的。这里接受所有类型的 Python 对象。跟踪历史记录的“Tensor”参数(即使用“requires_grad=True”)将在调用之前转换为不跟踪历史记录的参数，并且它们的使用将在图中注册。请注意，此逻辑不会遍历列表/字典/任何其他数据结构，并且只会考虑作为调用的直接参数的tensor。您可以返回单个 <code>Tensor</code> 输出，或者返回一个 <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code>tuple</code></a> 常量(如果存在)是多个输出。另外，请参阅 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 的文档来查找只能从 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code> 调用的有用方法的描述</a>.</li>
<li><code>setup_context()</code> (可选)。人们可以编写一个“组合”<a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a>，它接受<code>ctx</code> 对象或(从 PyTorch 2.0 开始)单独的 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a>，不接受 <code>ctx</code> 和发生 <code>ctx</code> 修改的 <code>setup_context()</code> 方法。 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 应该有计算，而 <code>setup_context()</code> 应该只负责 <code>ctx</code> 修改(并且没有任何计算)。一般来说单独的 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 和 <code>setup_context()</code> 是更接近PyTorch本机操作的工作方式，因此更适合与各种PyTorch子系统组合。有关更多详细信息，请参阅<a href="#combining-forward-context">组合或单独的forward()和setup_context()</a>。</li>
<li><a href="../generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward" title="torch.autograd.Function.backward"><code>backward()</code></a> (或 <code>vjp()</code> ) 定义梯度公式。它将给出“Tensor”参数与输出一样多，每个参数代表梯度 w.r.t。那个输出。重要的是切勿就地修改这些内容。它应该返回与输入一样多的tensor，每个tensor都包含梯度。其相应的输入。如果您的输入不需要梯度(“needs_input_grad”是一个布尔元组，指示每个输入是否需要梯度计算)，或者是非“Tensor”对象，则可以返回“python:None”。另外，如果您有 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 的可选参数，您可以返回梯度比输入更多，只要它们都是 <a href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><code>None</code></a> 。</li>
</ul>
<p><strong>步骤 2：</strong> 您有责任正确使用 <code>ctx</code> 中的函数，以确保新的 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.函数"><code>Function</code></a>与 autograd 引擎一起正常工作。</p>
<ul>
<li><a href="../generated/torch.autograd.function.FunctionCtx.save_for_backward.html#torch.autograd.function.FunctionCtx.save_for_backward" title="torch.autograd.function.FunctionCtx.save_for_backward"><code>save_for_backward()</code></a> 必须用于保存要在向后传递中使用的任何tensor。非tensor应直接存储在 ctx 上。如果既不是输入也不是输出的tensor被保存为后向，您的 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 可能不支持双后向(请参阅步骤 3)。</li>
<li><a href="../generated/torch.autograd.function.FunctionCtx.mark_dirty.html#torch.autograd.function.FunctionCtx.mark_dirty" title="torch.autograd.function.FunctionCtx.mark_dirty"><code>mark_dirty()</code></a> 必须是用于标记由前向函数就地修改的任何输入。</li>
<li><a href="../generated/torch.autograd.function.FunctionCtx.mark_non_Differentiable.html#torch.autograd.function.FunctionCtx.mark_non_Differentiable" title="torch.autograd.function.FunctionCtx.mark_non_Differentiable"><code>mark_non_Differentiable()</code></a> 必须用于告诉引擎输出是否不可微分。默认情况下，所有可微分类型的输出tensor都将设置为需要梯度。不可微分类型(即整数类型)的tensor永远不会被标记为需要梯度。</li>
<li><a href="../generated/torch.autograd.function.FunctionCtx.set_materialize_grads.html#torch.autograd.function.FunctionCtx.set_materialize_grads" title="torch.autograd.function.FunctionCtx.set_materialize_grads"><code>set_materialize_grads()</code></a> 可用于告诉 autograd 引擎在输出不依赖于输入的情况下优化梯度计算，方法是不具体化给予向后函数的梯度tensor。也就是说，如果设置为 False，Python 中的 None 对象或 C++ 中的“未定义tensor”(x.define() 为 False 的tensor x)在向后调用之前不会转换为用零填充的tensor，因此您的代码将需要像处理充满零的tensor一样处理此类对象。此设置的默认值为 True。</li>
</ul>
<p><strong>步骤 3：</strong> 如果你的 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 不支持双向后，你应该通过用 <code>向后装饰来显式声明这一点一次_可微分()</code> 。使用此装饰器，尝试通过函数执行双向后操作将产生错误。有关双向后操作的更多信息，请参阅我们的双向后教程。</p>
<p><strong>步骤4：</strong> 建议您使用 <a href="../generated/torch.autograd.gradcheck.html#torch.autograd.gradcheck" title="torch.autograd.gradcheck"><code>torch.autograd.gradcheck()</code></a>通过使用后向函数计算雅可比矩阵并将值逐元素与使用有限差分数值计算的雅可比矩阵进行比较，检查后向函数是否正确计算前向的梯度。</p>
<h3 id="_4">示例 <a href="#example" title="此标题的永久链接">¶</a></h3>
<p>您可以在下面找到“Linear”函数的代码以及附加注释：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a># Inherit from Function
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>class LinearFunction(Function):
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    # Note that forward, setup_context, and backward are @staticmethods
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    @staticmethod
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    def forward(input, weight, bias):
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>        output = input.mm(weight.t())
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        if bias is not None:
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>            output += bias.unsqueeze(0).expand_as(output)
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        return output
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    @staticmethod
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    # inputs is a Tuple of all of the inputs passed to forward.
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    # output is the output of the forward().
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    def setup_context(ctx, inputs, output):
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>        input, weight, bias = inputs
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        ctx.save_for_backward(input, weight, bias)
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    # This function has only a single output, so it gets only one gradient
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    @staticmethod
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    def backward(ctx, grad_output):
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        # This is a pattern that is very convenient - at the top of backward
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        # unpack saved_tensors and initialize all gradients w.r.t. inputs to
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>        # None. Thanks to the fact that additional trailing Nones are
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>        # ignored, the return statement is simple even when the function has
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>        # optional inputs.
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        input, weight, bias = ctx.saved_tensors
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>        grad_input = grad_weight = grad_bias = None
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        # These needs_input_grad checks are optional and there only to
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        # improve efficiency. If you want to make your code simpler, you can
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        # skip them. Returning gradients for inputs that don&#39;t require it is
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        # not an error.
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        if ctx.needs_input_grad[0]:
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>            grad_input = grad_output.mm(weight)
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        if ctx.needs_input_grad[1]:
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>            grad_weight = grad_output.t().mm(input)
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>        if bias is not None and ctx.needs_input_grad[2]:
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>            grad_bias = grad_output.sum(0)
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        return grad_input, grad_weight, grad_bias
</code></pre></div>
<p>现在，为了更轻松地使用这些自定义操作，我们建议对它们使用别名或将它们包装在函数中。包装在函数中让我们支持默认参数和关键字参数：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a># Option 1: alias
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>linear = LinearFunction.apply
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a># Option 2: wrap in a function, to support default args and keyword args.
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>def linear(input, weight, bias=None):
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    return LinearFunction.apply(input, weight, bias)
</code></pre></div>
<p>在这里，我们给出了由非tensor参数参数化的函数的另一个示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>class MulConstant(Function):
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    @staticmethod
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>    def forward(tensor, constant):
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>        return tensor * constant
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    @staticmethod
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    def setup_context(ctx, inputs, output):
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>        # ctx is a context object that can be used to stash information
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>        # for backward computation
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>        tensor, constant = inputs
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>        ctx.constant = constant
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    @staticmethod
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    def backward(ctx, grad_output):
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>        # We return as many input gradients as there were arguments.
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>        # Gradients of non-Tensor arguments to forward must be None.
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>        return grad_output * ctx.constant, None
</code></pre></div>
<p>在这里，我们通过调用 set_materialize_grads(False) 来优化上面的示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>class MulConstant(Function):
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    @staticmethod
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    def forward(tensor, constant):
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>        return tensor * constant
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    @staticmethod
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    def setup_context(ctx, inputs, output):
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>        tensor, constant = inputs
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>        ctx.set_materialize_grads(False)
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>        ctx.constant = constant
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    @staticmethod
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    def backward(ctx, grad_output):
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>        # Here we must handle None grad_output tensor. In this case we
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>        # can skip unnecessary computations and just return None.
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>        if grad_output is None:
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>            return None, None
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>        # We return as many input gradients as there were arguments.
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>        # Gradients of non-Tensor arguments to forward must be None.
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>        return grad_output * ctx.constant, None
</code></pre></div>
<p>如果您需要在 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 中计算任何“中间”tensor要保存，它们必须作为输出返回，或者组合 <code>forward</code> 和 <code>setup_context()</code> (请参阅<a href="#combining-forward-context">组合或单独的forward() 和 setup_context()</a> )请注意，这意味着如果您希望渐变流过这些中间值，则需要为它们定义渐变公式(另请参阅<a href="https://pytorch.org/tutorials/intermediate/custom_function_double_backward_tutorial.html">双向后教程</a> )：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>class MyCube(torch.autograd.Function):
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>    @staticmethod
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>    def forward(x):
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>        # We wish to save dx for backward. In order to do so, it must
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>        # be returned as an output.
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        dx = 3 * x ** 2
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>        result = x ** 3
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>        return result, dx
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    @staticmethod
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    def setup_context(ctx, inputs, output):
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>        x, = inputs
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        result, dx = output
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        ctx.save_for_backward(x, dx)
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>
<a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>    @staticmethod
<a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>    def backward(ctx, grad_output, grad_dx):
<a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>        x, dx = ctx.saved_tensors
<a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>        # In order for the autograd.Function to work with higher-order
<a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>        # gradients, we must add the gradient contribution of `dx`,
<a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>        # which is grad_dx * 6 * x.
<a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>        result = grad_output * dx + grad_dx * 6 * x
<a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>        return result
<a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
<a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a># Wrap MyCube in a function so that it is clearer what the output is
<a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>def my_cube(x):
<a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>    result, dx = MyCube.apply(x)
<a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>    return result
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">笔记</p>
<p><code>backward</code> 的输入，即 <code>grad_output</code> ，也可以是跟踪历史的tensor。因此，如果使用可微分操作实现“向后”(例如，调用另一个自定义 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> )，则高阶导数将起作用在这种情况下，用 <code>save_for_backward</code> 保存的tensor也可以在向后使用，并且有梯度回流，但保存在 <code>ctx</code> 中的tensor不会有梯度回流。如果你需要梯度对于保存在 <code>ctx</code> 中的 Tensor 的流回，您应该将其作为自定义 <code>Function</code> 的输出，并使用 <code>save_for_backward</code> 保存它。</p>
</div>
<p>您可能想检查您实现的后向方法是否实际计算了函数的导数。通过使用小的有限差分与数值近似进行比较是可能的：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>from torch.autograd import gradcheck
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a># gradcheck takes a tuple of tensors as input, check if your gradient
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a># evaluated with these tensors are close enough to numerical
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a># approximations and returns True if they all verify this condition.
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True))
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>test = gradcheck(linear, input, eps=1e-6, atol=1e-4)
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>print(test)
</code></pre></div>
<p>有关有限差分梯度比较的更多详细信息，请参阅<a href="../autograd.html#grad-check">数值梯度检查</a>。如果您的函数用于高阶导数(区分向后传递)，您可以使用“gradgradcheck”函数从同一包检查高阶导数。</p>
<h3 id="forward-setup_context">组合或单独的 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 和 <code>setup_context()</code><a href="#combined-or-separate-forward-and-setup-context" title="此标题的永久链接">¶</a></h3>
<p>定义 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 的主要方法有两种。任何一个：</p>
<ul>
<li>定义一个将前向计算逻辑与<code>setup_context()</code></li>
<li>(从 PyTorch 2.0 开始)定义一个单独的 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch. autograd.Function.forward"><code>forward()</code></a> 和 <code>setup_context()</code></li>
</ul>
<p>我们推荐第二个选项(单独的 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 和 <code>setup _context()</code> )因为这更接近 PyTorch 本机操作的实现方式，并且它由 <a href="../func.api.html#module-torch.func" title="torch.func"><code>torch.func</code></a> 转换组成。但是，我们计划未来支持这两种方法；结合 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 与 <code>setup_context()</code> ：带来更大的灵活性，因为您可以保存中间体而不将它们作为输出返回。</p>
<p>请参阅上一节了解如何使用单独的 <a href="https://pytorch.org/docs/stable/generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 和 <code>setup_context()</code> 定义 <a href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a>。</p>
<p>以下是如何结合使用 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 和<code>setup_context()</code>来定义 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 的示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>class LinearFunction(Function):
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>    @staticmethod
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>    # ctx is the first argument to forward
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>    def forward(ctx, input, weight, bias=None):
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>        # The forward pass can use ctx.
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>        ctx.save_for_backward(input, weight, bias)
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>        output = input.mm(weight.t())
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>        if bias is not None:
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>            output += bias.unsqueeze(0).expand_as(output)
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>        return output
<a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>
<a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>    @staticmethod
<a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>    def backward(ctx, grad_output):
<a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>        input, weight, bias = ctx.saved_tensors
<a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>        grad_input = grad_weight = grad_bias = None
<a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>
<a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>        if ctx.needs_input_grad[0]:
<a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>            grad_input = grad_output.mm(weight)
<a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>        if ctx.needs_input_grad[1]:
<a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>            grad_weight = grad_output.t().mm(input)
<a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>        if bias is not None and ctx.needs_input_grad[2]:
<a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>            grad_bias = grad_output.sum(0)
<a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>
<a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>        return grad_input, grad_weight, grad_bias
</code></pre></div>
<h3 id="ad">转发模式 AD <a href="#forward-mode-ad" title="永久链接到此标题">¶</a></h3>
<p>覆盖正向模式 AD 公式具有非常相似的 API，但有一些不同的微妙之处。您可以实现 <a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 函数。</p>
<p>它将被给予与输入一样多的“Tensor”参数，每个参数代表梯度 w.r.t。该输入。它应该返回与输出一样多的tensor，每个tensor都包含梯度。其相应的输出。 <a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 将在之后调用<a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 方法，在 <code>apply()</code> 之前返回。</p>
<p><a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 与 <a href="../generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward" title="torch.autograd.Function.backward"><code>forward()</code></a> 函数：</p>
<ul>
<li>您可以使用 ctx 传递来自 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 到 <a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 函数。如果该状态将<a href="../generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward" title="torch.autograd.Function.backward"><code>backward()</code></a> 不需要，您可以显式释放通过在 <a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function"><code>jvp()</code></a> 函数。</li>
<li><a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 的实现必须是向后可微的，或者显式检查给定的前向模式梯度中没有一个设置了 <code>requires_grad</code>。</li>
<li><a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 函数必须与 <a href="../generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward" title="torch.autograd.Function.forward"><code>forward()</code></a> 。例如，如果第 i 个输入被就地修改，则第 i 个梯度必须就地更新。类似地，如果第 j 个输出是第 k 个输入的视图。那么返回的第 j 个输出梯度必须是给定的第 k 个输入梯度的视图。</li>
<li>因为用户无法指定需要计算哪个梯度，所以 <a href="../generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp" title="torch.autograd.Function.jvp"><code>jvp()</code></a> 函数应该始终计算所有输出的梯度。</li>
<li>前向模式梯度确实遵循 <a href="../generated/torch.autograd.function.FunctionCtx.set_materialize_grads.html#torch.autograd.function.FunctionCtx.set_materialize_grads" title="torch.autograd.function.FunctionCtx.set_materialize_grads"><code>set_materialize_grads()</code></a> 你可以得到禁用此功能时，无输入渐变。</li>
</ul>
<h3 id="torchfunc-torchvmap"><a href="../func.api.html#module-torch.func" title="torch.func"><code>torch.func</code></a> 转换和/或 <a href="../generated/torch.vmap.html#torch.vmap" title="torch.vmap"><code>torch.vmap()</code></a><a href="#torch-func-transforms-and-or-torch-vmap" title="此标题的永久链接">¶</a></h3>
<p>有关详细信息，请参阅<a href="extending.func.html#func-autograd-function">使用 autograd.Function 扩展 torch.func</a>。</p>
<h2 id="torchnn">扩展 <a href="../nn.html#module-torch.nn" title="torch.nn"><code>torch.nn</code></a><a href="#extending-torch-nn" title="永久链接到此标题">¶</a></h2>
<p><a href="../nn.html#module-torch.nn" title="torch.nn"><code>nn</code></a> 导出两种接口 
- 模块及其功能版本。您可以以两种方式扩展它，但我们建议对所有类型的层使用模块，以保存任何参数或缓冲区，并建议使用函数形式的无参数操作，如激活函数、池化等。</p>
<p>上面的部分已经完全介绍了添加操作的功能版本。</p>
<h3 id="module">添加一个 <a href="../generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><code>Module</code></a><a href="#adding-a-module" title="永久链接到这个标题">¶</a></h3>
<p>由于 <a href="../nn.html#module-torch.nn" title="torch.nn"><code>nn</code></a> 大量利用 <a href="../autograd.html#module-torch.autograd" title="torch.autograd"><code>autograd</code></a> ，添加新的 <a href="../generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><code>Module</code></a> 需要实现 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a> 执行操作并可以计算梯度。从现在开始，假设我们想要实现一个“Linear”模块，并且我们已经实现了上面列表中的函数。添加此功能只需很少的代码。现在，有两个功能需要实现：</p>
<ul>
<li><code>__init__</code> ( <em>可选</em> ) - 接受内核大小、特征数量等参数并初始化参数和缓冲区。</li>
<li><a href="../generated/torch.nn.Module.html#torch.nn.Module.forward" title="torch.nn.Module.forward"><code>forward()</code></a> - 实例化一个 <a href="../autograd.html#torch.autograd.Function" title="torch.autograd.Function"><code>Function</code></a>并使用它来执行操作。它与上面所示的功能包装非常相似。</li>
</ul>
<p>这是“Linear”模块的实现方式：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>class Linear(nn.Module):
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>    def __init__(self, input_features, output_features, bias=True):
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>        super().__init__()
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>        self.input_features = input_features
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>        self.output_features = output_features
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>        # nn.Parameter is a special kind of Tensor, that will get
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>        # automatically registered as Module&#39;s parameter once it&#39;s assigned
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>        # as an attribute. Parameters and buffers need to be registered, or
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>        # they won&#39;t appear in .parameters() (doesn&#39;t apply to buffers), and
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>        # won&#39;t be converted when e.g. .cuda() is called. You can use
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>        # .register_buffer() to register buffers.
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>        # nn.Parameters require gradients by default.
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>        self.weight = nn.Parameter(torch.empty(output_features, input_features))
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>        if bias:
<a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>            self.bias = nn.Parameter(torch.empty(output_features))
<a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>        else:
<a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>            # You should always register all possible parameters, but the
<a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>            # optional ones can be None if you want.
<a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a>            self.register_parameter(&#39;bias&#39;, None)
<a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>
<a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a>        # Not a very smart way to initialize weights
<a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a>        nn.init.uniform_(self.weight, -0.1, 0.1)
<a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a>        if self.bias is not None:
<a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a>            nn.init.uniform_(self.bias, -0.1, 0.1)
<a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a>
<a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a>    def forward(self, input):
<a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a>        # See the autograd section for explanation of what happens here.
<a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a>        return LinearFunction.apply(input, self.weight, self.bias)
<a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a>
<a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a>    def extra_repr(self):
<a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a>        # (Optional)Set the extra information about this module. You can test
<a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a>        # it by printing an object of this class.
<a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a>        return &#39;input_features={}, output_features={}, bias={}&#39;.format(
<a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a>            self.input_features, self.output_features, self.bias is not None
<a id="__codelineno-7-36" name="__codelineno-7-36" href="#__codelineno-7-36"></a>        )
</code></pre></div>
<h2 id="torch-python-api">扩展 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> Python API <a href="#extending-torch-python-api" title="永久链接到此标题">¶</a></h2>
<p>您可以通过使用与 “Tensor” 匹配的方法定义自定义类来创建模拟 Tensor 的自定义类型。 但是，如果您希望能够将这些类型传递给顶级 torch 命名空间中接受 <a href="https://pytorch.org/docs/stable/torch.html#module-torch">Tensor</a> 操作数的 <a href="../generated/torch.add.html#torch.add" title="torch.add"><code>torch.add()</code></a> 等函数，该怎么办？</p>
<p>如果您的自定义 Python 类型定义了一个名为 <code>__torch_function__</code> 的方法，当您的自定义类的实例传递给以下函数时，PyTorch 将调用您的 <code>__torch_function__</code> 实现<a href="../torch.html#module-torch" title="torch"><code>torch</code></a> 命名空间。这使得可以为您的 <code>__torch_function__</code> 实现的 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> 命名空间中的任何函数定义自定义实现可以调用，允许您的用户将您的自定义类型与他们已经为“Tensor”编写的现有 PyTorch 工作流程结合使用。这适用于与“Tensor”无关的“duck”类型以及用户定义的“Tensor”子类。</p>
<h3 id="tensor-torch">使用类似 <code>Tensor</code> 类型扩展 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> <a href="#extending-torch-with-a-tensor-like-type" title="此标题的永久链接">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">笔记</p>
<p>此功能受到 NumPy <code>__array_function__</code> 协议的启发。请参阅 <a href="https://numpy.org/doc/stable/user/basics.dispatch.html#basics-dispatch">NumPy 文档</a> 和 <a href="https://numpy.org/neps/nep-0018-array-function-protocol.html">NEP-0018</a>了解更多详细信息。</p>
</div>
<p>为了具体说明这一点，让我们从一个简单的示例开始，说明 API 调度机制。我们将创建一个表示 2D 标量tensor的自定义类型，由阶数“N”和沿对角线条目的值“value”进行参数化：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>class ScalarTensor(object):
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>   def __init__(self, N, value):
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>       self._N = N
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>       self._value = value
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>   def __repr__(self):
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>       return &quot;ScalarTensor(N={}, value={})&quot;.format(self._N, self._value)
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>   def tensor(self):
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>       return self._value * torch.eye(self._N)
</code></pre></div>
<p>设计的第一次迭代并不是很有用。 <code>ScalarTensor</code> 的主要功能是提供比基本tensor类更紧凑的标量tensor字符串表示形式：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>&gt;&gt;&gt; d = ScalarTensor(5, 2)
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>&gt;&gt;&gt; d
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>ScalarTensor(N=5, value=2)
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>&gt;&gt;&gt; d.tensor()
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>tensor([[2., 0., 0., 0., 0.],
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a> [0., 2., 0., 0., 0.],
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a> [0., 0., 2., 0., 0.],
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a> [0., 0., 0., 2., 0.],
<a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a> [0., 0., 0., 0., 2.]])
</code></pre></div>
<p>如果我们尝试将此对象与 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 一起使用，我们将遇到问题：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>&gt;&gt;&gt; import torch
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>&gt;&gt;&gt; torch.mean(d)
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>TypeError: mean(): argument &#39;input&#39; (position 1) must be Tensor, not ScalarTensor
</code></pre></div>
<p>在<code>ScalarTensor</code>中添加<code>__torch_function__</code>实现使得上述操作能够成功。让我们重新实现我们的实现，这次添加一个 <code>__torch_function__</code> 实现：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>HANDLED_FUNCTIONS = {}
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>class ScalarTensor(object):
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    def __init__(self, N, value):
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>        self._N = N
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>        self._value = value
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    def __repr__(self):
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>        return &quot;ScalarTensor(N={}, value={})&quot;.format(self._N, self._value)
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>    def tensor(self):
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>        return self._value * torch.eye(self._N)
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>    @classmethod
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>    def __torch_function__(cls, func, types, args=(), kwargs=None):
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>        if kwargs is None:
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>            kwargs = {}
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>        if func not in HANDLED_FUNCTIONS or not all(
<a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>            issubclass(t, (torch.Tensor, ScalarTensor))
<a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>            for t in types
<a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>        ):
<a id="__codelineno-11-21" name="__codelineno-11-21" href="#__codelineno-11-21"></a>            return NotImplemented
<a id="__codelineno-11-22" name="__codelineno-11-22" href="#__codelineno-11-22"></a>        return HANDLED_FUNCTIONSfunc
</code></pre></div>
<p><code>__torch_function__</code> 方法有四个参数：<code>func</code>，对要重写的 torch API 函数的引用，types，实现 <code>__torch_function__</code> 的类似 <code>Tensor</code> 的类型列表，<code>args</code>，传递给函数的参数元组，以及 <code>kwargs</code>， 传递给函数的关键字参数的字典。 它使用名为 <code>HANDLED_FUNCTIONS</code> 的全局调度表来存储自定义实现。 该字典的键是 <code>torch</code> 命名空间中的函数，值是 <code>ScalarTensor</code> 的实现。</p>
<div class="admonition note">
<p class="admonition-title">笔记</p>
<p>使用全局调度表不是 <code>__torch_function__</code> API 的强制部分，它只是用于构建覆盖实现的有用设计模式。</p>
</div>
<p>当我们向它传递一个“ScalarTensor”时，这个类定义不足以使“torch.mean”做正确的事情——我们还需要为“ScalarTensor”操作数定义“torch.mean”的实现，并将该实现添加到“ HANDLED_FUNCTIONS` 调度表字典。一种方法是定义一个装饰器：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>import functools
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>def implements(torch_function):
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a> &quot;&quot;&quot;Register a torch function override for ScalarTensor&quot;&quot;&quot;
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    def decorator(func):
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>        functools.update_wrapper(func, torch_function)
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>        HANDLED_FUNCTIONS[torch_function] = func
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>        return func
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>    return decorator
</code></pre></div>
<p>这可以应用于我们的覆盖的实现：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>@implements(torch.mean)
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>def mean(input):
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>    return float(input._value) / input._N
</code></pre></div>
<p>通过此更改，我们现在可以将 <code>torch.mean</code> 与 <code>ScalarTensor</code> 一起使用：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>&gt;&gt;&gt; d = ScalarTensor(5, 2)
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>&gt;&gt;&gt; torch.mean(d)
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>0.4
</code></pre></div>
<p>当然，“torch.mean”是最简单的重写函数示例，因为它只需要一个操作数。我们可以使用相同的机制来重写需要多个操作数的函数，其中任何一个都可能是定义 <code>__torch_function__</code> 的tensor或类tensor，例如 <a href="../generated/torch.add.html#torch.add" title="torch.add"><code>torch.add ()</code></a> :</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>def ensure_tensor(data):
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>    if isinstance(data, ScalarTensor):
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>        return data.tensor()
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>    return torch.as_tensor(data)
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>@implements(torch.add)
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>def add(input, other):
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>   try:
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>       if input._N == other._N:
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>           return ScalarTensor(input._N, input._value + other._value)
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>       else:
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>           raise ValueError(&quot;Shape mismatch!&quot;)
<a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>   except AttributeError:
<a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>       return torch.add(ensure_tensor(input), ensure_tensor(other))
</code></pre></div>
<p>当两个操作数都是“ScalarTensor”实例时，此版本有一个快速路径，当两个操作数不是“ScalarTensor”时，该版本还有一个较慢的路径，该路径会降级为将数据转换为tensor。当任一操作数是“ScalarTensor”或常规“Tensor”时，这使得重写函数正确：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>&gt;&gt;&gt; s = ScalarTensor(2, 2)
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>&gt;&gt;&gt; torch.add(s, s)
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>ScalarTensor(N=2, value=4)
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>&gt;&gt;&gt; t = torch.tensor([[1, 1,], [1, 1]])
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>&gt;&gt;&gt; torch.add(s, t)
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>tensor([[3., 1.],
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a> [1., 3.]])
</code></pre></div>
<p>请注意，我们的 add 实现不采用 alpha 或 out 作为关键字参数，例如 <a href="../generated/torch.add.html#torch.add" title="torch.add"><code>torch.add()</code></a> 做：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>&gt;&gt;&gt; torch.add(s, s, alpha=2)
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>TypeError: add() got an unexpected keyword argument &#39;alpha&#39;
</code></pre></div>
<p>为了速度和灵活性，<code>__torch_function__</code> 调度机制不会检查覆盖函数的签名是否与 <a href="../torch.html#模块火炬“火炬”"><code>torch</code></a>API。对于某些应用程序，忽略可选参数是可以的，但为了确保与“Tensor”完全兼容，torch API 函数的用户实现应注意精确模拟被覆盖函数的 API。</p>
<p><a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 中没有显式覆盖的函数将从 <code>__torch_function__</code> 返回 <code>NotImplemented</code> 。如果所有定义了 <code>__torch_function__</code> 的操作数都返回 <code>NotImplemented</code> ，PyTorch 将引发 <code>TypeError</code> 。这意味着大多数时候，当传递此类类型的实例时，没有显式覆盖类型的操作将引发“TypeError”：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>&gt;&gt;&gt; torch.mul(s, 3)
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>TypeError: no implementation found for &#39;torch.mul&#39; on types that
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>implement __torch_function__: [ScalarTensor]
</code></pre></div>
<p>实际上，这意味着如果您想使用 <code>__torch_function__</code> 实现来实现覆盖，您将需要显式实现完整的 <a href="../torch.html #module-torch" title="torch"><code>torch</code></a> API 或您关心的用例的 API 的整个子集。这可能是一个艰巨的任务，因为完整的 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 非常广泛。</p>
<p>另一种选择是对于未处理的操作不返回“NotImplemented”，而是在没有覆盖时将“Tensor”传递给原始的 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> 函数可用的。例如，如果我们将 <code>ScalarTensor</code> 的 <code>__torch_function__</code> 的实现更改为以下之一：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>@classmethod
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>def __torch_function__(cls, func, types, args=(), kwargs=None):
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>    if kwargs is None:
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>        kwargs = {}
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>    if func not in HANDLED_FUNCTIONS or not all(
<a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>            issubclass(t, (torch.Tensor, ScalarTensor))
<a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a>            for t in types
<a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a>        ):
<a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a>        args = [a.tensor() if hasattr(a, &#39;tensor&#39;) else a for a in args]
<a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>        return func(*args, **kwargs)
<a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a>    return HANDLED_FUNCTIONSfunc
</code></pre></div>
<p>然后 <a href="../generated/torch.mul.html#torch.mul" title="torch.mul"><code>torch.mul()</code></a> 将正常工作，尽管Return type始终是 <code>Tensor</code> 而不是 <code>ScalarTensor</code> ，即使两个操作数都是 <code>ScalarTensor</code> 实例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>&gt;&gt;&gt; s = ScalarTensor(2, 2)
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>&gt;&gt;&gt; torch.mul(s, s)
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>tensor([[4., 0.],
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a> [0., 4.]])
</code></pre></div>
<p>另请参阅下面的“MetadataTensor”示例，了解此模式的另一种变体，但始终返回“MetadataTensor”以通过 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 中的操作传播元数据。</p>
<p><code>__torch_function__</code> 协议旨在完全覆盖 API，部分覆盖可能会导致不良结果，特别是某些函数会引发 <code>TypeError</code> 。对于子类尤其如此，其中 torch.add 、 torch.Tensor.<strong>add</strong> 和 torch.Tensor.add 的所有三个都必须被覆盖，即使它们返回完全相同的结果。如果不这样做也可能导致无限递归。如果需要实现 <code>torch.Tensor</code> 子类中的函数，则必须在其实现中使用 <code>super().__torch_function__</code> 。</p>
<h3 id="torchtensor">子类化 <code>torch.Tensor</code><a href="#subclassing-torch-tensor" title="永久链接到此标题">¶</a></h3>
<p>从版本 1.7.0 开始，应用于“torch.Tensor”子类的“torch.Tensor”上的方法和公共“torch.*”命名空间中的函数将返回子类实例，而不是“torch.Tensor”实例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>&gt;&gt;&gt; class SubTensor(torch.Tensor):
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>...     pass
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>&gt;&gt;&gt; type(torch.add(SubTensor([0]), SubTensor([1]))).__name__
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>&#39;SubTensor&#39;
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>&gt;&gt;&gt; type(torch.add(SubTensor([0]), torch.tensor([1]))).__name__
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>&#39;SubTensor&#39;
</code></pre></div>
<p>如果存在多个子类，则默认选择层次结构中最低的一个。如果没有唯一的方法来确定这种情况，则会引发“TypeError”：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>&gt;&gt;&gt; type(torch.add(SubTensor2([0]), SubTensor([1]))).__name__
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>&#39;SubTensor2&#39;
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>&gt;&gt;&gt; type(torch.add(SubTensor2([0]), torch.tensor([1]))).__name__
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>&#39;SubTensor2&#39;
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>&gt;&gt;&gt; torch.add(SubTensor([0]), OtherSubTensor([1]))
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>Traceback (most recent call last):
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a>TypeError: no implementation found for &#39;torch.add&#39; on types that implement __torch_function__: [SubTensor, OtherSubTensor]
</code></pre></div>
<p>如果希望对所有tensor方法进行全局覆盖，可以使用 <code>__torch_function__</code> 。这是一个记录所有函数/方法调用的示例：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>class LoggingTensor(torch.Tensor):
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>    @classmethod
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>    def __torch_function__(cls, func, types, args=(), kwargs=None):
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>        # NOTE: Logging calls Tensor.__repr__, so we can&#39;t log __repr__ without infinite recursion
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>        if func is not torch.Tensor.__repr__:
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>            logging.info(f&quot;func: {func.__name__}, args: {args!r}, kwargs: {kwargs!r}&quot;)
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>        if kwargs is None:
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>            kwargs = {}
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a>        return super().__torch_function__(func, types, args, kwargs)
</code></pre></div>
<p>但是，如果希望重写 Tensor 子类上的方法，则可以通过直接重写该方法(通过为子类定义它)或使用 <code>__torch_function__</code> 和与 <code>func</code> 匹配。</p>
<p>在 <code>__torch_function__</code> 中应该小心，因为子类总是调用 <code>super().__torch_function__(func,...)</code> 而不是直接调用 <code>func</code> ，和1.7.0版本之前的情况一样。如果不这样做，可能会导致 <code>func</code> 递归回 <code>__torch_function__</code> ，从而导致无限递归。</p>
<h3 id="tensor-torch_1">使用 <code>Tensor</code> 包装类型扩展 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> <a href="#extending-torch-with-a-tensor-wrapper-type" title="此标题的永久链接">¶</a></h3>
<p>另一个有用的例子是包装 <code>Tensor</code> 的类型，无论是作为属性还是通过子类化。下面我们实现了这种类型的一个特殊情况，一个“MetadataTensor”，它将元数据字典附加到通过 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> 传播的“Tensor”运营。由于这是完整 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 的通用包装，因此我们不需要单独实现每个覆盖，因此我们可以制作 <code>__torch _function__</code> 实现对于允许哪些操作更加宽松：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>class MetadataTensor(object):
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>    def __init__(self, data, metadata=None, **kwargs):
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>        self._t = torch.as_tensor(data, **kwargs)
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>        self._metadata = metadata
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>    def __repr__(self):
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>        return &quot;Metadata:
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>{}
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>data:
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>{}&quot;.format(self._metadata, self._t)
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a>    @classmethod
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a>    def __torch_function__(cls, func, types, args=(), kwargs=None):
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a>        if kwargs is None:
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a>            kwargs = {}
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a>        metadatas = tuple(a._metadata for a in args if hasattr(a, &#39;_metadata&#39;))
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a>        args = [getattr(a, &#39;_t&#39;, a) for a in args]
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a>        assert len(metadatas) &gt; 0
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a>        ret = func(*args, **kwargs)
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a>        return MetadataTensor(ret, metadata=metadatas[0])
</code></pre></div>
<p>这个简单的实现不一定适用于 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API 中的每个函数，但它足以捕获最常见的操作：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>&gt;&gt;&gt; metadata = {&#39;owner&#39;: &#39;Ministry of Silly Walks&#39;}
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>&gt;&gt;&gt; m = MetadataTensor([[1, 2], [3, 4]], metadata=metadata)
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>&gt;&gt;&gt; t = torch.tensor([[1, 2], [1, 2]])
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>&gt;&gt;&gt; torch.add(t, m)
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>Metadata:
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>{&#39;owner&#39;: &#39;Ministry of Silly Walks&#39;}
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a>data:
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a>tensor([[2, 4],
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a> [4, 6]])
<a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a>&gt;&gt;&gt; torch.mul(t, m)
<a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a>Metadata:
<a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a>{&#39;owner&#39;: &#39;Ministry of Silly Walks&#39;}
<a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a>
<a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a>data:
<a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a>tensor([[1, 4],
<a id="__codelineno-25-17" name="__codelineno-25-17" href="#__codelineno-25-17"></a> [3, 8]])
</code></pre></div>
<h3 id="__torch_function__">对定义 <code>__torch_function__</code> 的多种类型进行操作<a href="#operations-on-multiple-types-that-define-torch-function" title="Permalink to this header">¶</a></h3>
<p>可以将 torch API 与多个不同类型一起使用，每个类型都有一个 <code>__torch_function__</code> 实现，但必须特别小心。在这种情况下，规则是：</p>
<ul>
<li>调度操作为每个操作数收集 <code>__torch_function__</code> 的所有不同实现，并按顺序调用它们：子类在超类之前，否则在运算符表达式中从左到右。</li>
<li>如果除 <code>之外的任何值返回 NotImplemented</code>，该值作为结果返回。实现可以通过返回 <code>NotImplemented</code> 来表明它们没有实现操作。*如果所有 <code>__torch_function__</code> 实现都返回 <code>NotImplemented</code> ，PyTorch 会引发 <code>TypeError</code> 。</li>
</ul>
<h3 id="pytorch-api">测试 PyTorch API 覆盖的覆盖率 <a href="#testing-coverage-of-overrides-for-the-pytorch-api" title="Permalink to this header">¶</a></h3>
<p>实现 <code>__torch_function__</code> 的一个麻烦的方面是，如果某些操作有覆盖，而其他操作没有覆盖，那么用户充其量会看到不一致的体验，或者最坏的情况是在使用函数时会看到运行时引发的错误没有覆盖。为了简化此过程，PyTorch 提供了面向开发人员的 API，以确保完全支持 <code>__torch_function__</code> 覆盖。此 API 是私有的，将来可能会在没有警告的情况下进行更改。</p>
<p>首先，要获取所有可重写函数的列表，请使用 <code>torch.overrides._get_overridable_functions</code> 。这会返回一个字典，其键是“PyTorch”Python API 中的命名空间，其值是该命名空间中可以覆盖的函数列表。例如，让我们打印 <code>torch.nn.function</code> 中可以被覆盖的前 5 个函数的名称：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>&gt;&gt;&gt; from torch.overrides import get_overridable_functions
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>&gt;&gt;&gt; func_dict = get_overridable_functions()
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>&gt;&gt;&gt; nn_funcs = func_dict[torch.nn.functional]
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>&gt;&gt;&gt; print([f.__name__ for f in nn_funcs[:5])
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>[&#39;adaptive_avg_pool1d&#39;, &#39;adaptive_avg_pool2d&#39;, &#39;adaptive_avg_pool3d&#39;,
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a> &#39;adaptive_max_pool1d&#39;, &#39;adaptive_max_pool1d_with_indices&#39;]
</code></pre></div>
<p>这个函数列表使得迭代所有可重写函数成为可能，但实际上，如果不费力地手动复制每个测试的每个函数的签名，这还不足以为所有这些函数编写测试。为了简化此过程，“torch.overrides._get_testing_overrides”函数返回一个字典，将“PyTorch”API 中的可重写函数映射到与原始函数具有相同签名但无条件返回 -1 的虚拟 lambda 函数。这些函数与“inspect”一起使用来分析原始“PyTorch”函数的函数签名最有用：</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>&gt;&gt;&gt; import inspect
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>&gt;&gt;&gt; from torch.overrides import get_testing_overrides
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>&gt;&gt;&gt; override_dict = get_testing_overrides()
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>&gt;&gt;&gt; dummy_add = override_dict[torch.add]
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>&gt;&gt;&gt; inspect.signature(dummy_add)
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>&lt;Signature (input, other, out=None)&gt;
</code></pre></div>
<p>最后， <code>torch.overrides.get_ignored_functions</code> 返回一个明确不能被 <code>__torch_function__</code> 覆盖的函数元组。此列表可用于确认“get_overridable_functions”返回的字典中不存在的函数无法被覆盖。</p>
<h2 id="torch-api">扩展 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> 原生 API <a href="#extending-torch-native-api" title="永久链接到此标题">¶</a></h2>
<p>虽然 <code>__torch_function__</code> 允许人们有效地扩展 PyTorch 的纯 Python 组件的行为，但它不允许人们扩展用 C++ 实现的 PyTorch 部分。 为此，Tensor 子类还可以定义 <code>__torch_dispatch__</code> ，它将能够覆盖 C++ 级别的行为。</p>
<p>为了有效地使用此功能，了解 PyTorch 的本机部分是如何实现的非常重要。 最重要的组件是我们所说的“调度程序”(最好的描述可以在这篇<a href="http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/">博客文章</a>，尽管它有点过时了)。 正如其名称所暗示的，它负责为特定的函数调用调用正确的后端函数。 例如，当调用 torch.add(a, b) 时，调度程序将检查两个参数，找出哪个“功能”(autograd、autocast、功能化等)和哪个“后端”(CPU、CUDA、MPS 等) 应该用于此特定调用并最终调用所有正确的内核。 内核所做的一个非常常见的事情是“重新调度”。 例如，当使用 autocast 在 GPU 上运行神经网络时，第一个调用将是 autocast 内核，它将处理任何潜在的 autocast 逻辑并向下重新调度。 下一个功能将是 autograd，它将正确创建 autograd 图，然后重新调度。 最后，我们到达 CUDA 的后端内核，它将启动正确的 CUDA 内核并返回最终结果。 在退出时，autograd 会将图形附加到输出，最后，autocast 将有机会在退出时进行所需的任何更新。</p>
<p>调度程序的一种配置是调用所有这些功能和后端键的顺序。 最新列表及其顺序可以在 DispatchKey 枚举内的 DispatchKey.h 中找到。 为了扩展 torch 的目的，本次讨论的重要顺序子集是：<code>vmap -&gt; Autocast -&gt; Autograd -&gt; ZeroTensor -&gt; Neg/Conj -&gt; Functionize -&gt; Python -&gt; Backends</code>。 就本次讨论而言，最重要的关键是 Python，因为定义了 <code>__torch_dispatch__</code> 方法的每个 Tensor 子类都会调用此功能。 从那里调用用户定义的方法，并且可以任意覆盖行为。 从那里，再次调用提供的函数将执行“重新调度”。</p>
<p>此实现的一些重要含义是： </p>
<ul>
<li>此代码在“所有功能之下”运行。 因此，它只负责生成每个tensor的输出值，就像常规后端一样(并且可以并且应该忽略所有高级功能，例如 autograd、autocast 等)。 </li>
<li>如果任何高级功能在不重新分派的情况下实现给定函数，则它将永远不会到达 Python 键，因此 <code>__torch_dispatch__</code> 回调将永远不会被触发。 这种情况尤其发生在 CompositeImplicitAutograd 函数中，这些函数在 Autograd 级别进行评估而无需重新分派。 这是因为 CompositeImplicitAutograd 函数通过隐式调用其他本机操作来指定其 autograd 公式，因此在 Autograd 级别，该函数被分解为其本机操作，并对这些操作进行评估。 </li>
<li>回调 Python 以及包装结果时，将使用与常规 PyTorch Python/C++ 绑定相同的转换。 特别是，某些对象无法用 Python 表示，需要特殊处理(例如，未定义的tensor变为 None)。 </li>
<li>我们的本机函数被延迟填充为 torch.ops.{namespace}.{func_name}.{overload_name} 作为可调用的 Python 对象，以便能够从 Python 轻松地与它们交互。 赋予 <code>__torch_dispatch__</code>的 func 对象始终是此命名空间中的一个条目。 该命名空间可用于直接调用本机操作并绕过常用的 Python API 和绑定代码。</li>
</ul>
<p>与 <code>__torch_function__</code> 能够插入所有 torch 的 Python API 和 Tensor 方法类似， <code>__torch_dispatch__</code> 能够拦截对 aten 本机 API 的所有调用。 请注意，tensor上的所有方法在进入调度程序之前都会转换为函数调用，因此将在此处显示为函数调用：torch.add(a, 2) 和 a + 2 将导致完全相同的 aten 调用。 大多数这些函数都在 native_functions.yaml 中定义，它指定了这些函数的属性及其后端实现。 然后，它们的实现以及指定的功能将通过 codegen 自动注册。 一些更奇特的函数或特性也在 C++ 代码库或用户定义的 C++ 扩展中的其他位置注册。</p>
<p>还可以使用 torch.library 添加新的本机函数。 此 Python 功能允许定义和/或添加新的实现到本机函数。 这可用于添加缺少的内核、替换现有内核或定义全新的本机函数。</p>
<p>您可以在 <a href="https://github.com/albanD/subclass_zoo">subclass Zoo</a> 存储库中找到许多基于 <code>__torch_dispatch__</code> 的子类示例。</p>
<h2 id="torch-api_1">使用模式扩展所有 <a href="../torch.html#module-torch" title="torch"><code>torch</code></a> API <a href="#extending-all-torch-api-with-modes" title="永久链接到此标题">¶</a></h2>
<p>TODO 问：不接受tensor输入的函数怎么样？</p>
<p>TODO 模式概念介绍</p>
<p>TODO 日志记录模式示例</p>
<h2 id="c">编写自定义 C++ 扩展 <a href="#writing-custom-c-extensions" title="永久链接到此标题">¶</a></h2>
<p>有关详细说明和示例，请参阅此 <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">PyTorch 教程</a>。</p>
<p>文档可在 <a href="../cpp_extension.html">torch.utils.cpp_extension</a> 获取。</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../ddp/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Distributed Data Parallel">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Distributed Data Parallel
              </div>
            </div>
          </a>
        
        
          
          <a href="../extending.func/" class="md-footer__link md-footer__link--next" aria-label="Next: Extending torch.func with autograd.Function">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Extending torch.func with autograd.Function
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer"], "search": "../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.8fd75fb4.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>